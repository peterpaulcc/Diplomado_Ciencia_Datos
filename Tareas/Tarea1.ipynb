{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6053920",
   "metadata": {},
   "source": [
    "# Introducción a BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0ae91",
   "metadata": {},
   "source": [
    "**Nombre**: (Pedro Pablo Calderón)\n",
    "**Perfil**: (Estudiante de Economía de último semestre, interesado en el desarrollo de Modelos de Machine Learning con aplicaciones en pronóstico de variables macroeconómicas.)\n",
    "![Imagen de Autor](meup.jpeg) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0333d1",
   "metadata": {},
   "source": [
    "BERT, o Bidirectional Encoder Representations from Transformers, es un modelo de procesamiento del lenguaje natural (NLP) desarrollado por Google. Es especialmente poderoso para una variedad de tareas de NLP, como clasificación de texto, respuesta a preguntas, y más.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37c91d",
   "metadata": {},
   "source": [
    "## Arquitectura\n",
    "La arquitectura de BERT utiliza transformadores, que son una forma de red neuronal que utiliza mecanismos de atención para capturar información contextual desde todas las posiciones en una secuencia de texto. A diferencia de los modelos unidireccionales, BERT lee el texto en ambas direcciones, permitiendo una comprensión más rica y matizada del contexto.\n",
    "\n",
    "**Fórmula de Atención en Transformadores**:\n",
    "\n",
    "$$ \\text{Atención}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09992f4",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "BERT se puede utilizar para la clasificación de texto. Por ejemplo, en una tarea de análisis de sentimientos, BERT puede ser entrenado para categorizar opiniones como positivas o negativas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4683a",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "- [Blog de Google AI](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
